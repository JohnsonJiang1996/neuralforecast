{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from distutils.util import strtobool\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the contents in a .tsf file into a dataframe and returns it along with other meta-data of the dataset: frequency, horizon, whether the dataset contains missing values and whether the series have equal lengths\n",
    "#\n",
    "# Parameters\n",
    "# full_file_path_and_name - complete .tsf file path\n",
    "# replace_missing_vals_with - a term to indicate the missing values in series in the returning dataframe\n",
    "# value_column_name - Any name that is preferred to have as the name of the column containing series values in the returning dataframe\n",
    "def convert_tsf_to_dataframe(\n",
    "    full_file_path_and_name,\n",
    "    replace_missing_vals_with=\"NaN\",\n",
    "    value_column_name=\"series_value\",\n",
    "):\n",
    "    col_names = []\n",
    "    col_types = []\n",
    "    all_data = {}\n",
    "    line_count = 0\n",
    "    frequency = None\n",
    "    forecast_horizon = None\n",
    "    contain_missing_values = None\n",
    "    contain_equal_length = None\n",
    "    found_data_tag = False\n",
    "    found_data_section = False\n",
    "    started_reading_data_section = False\n",
    "\n",
    "    #with open(full_file_path_and_name, \"r\", encoding=\"cp1252\") as file:\n",
    "    with open(full_file_path_and_name, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            # Strip white space from start/end of line\n",
    "            line = line.strip()\n",
    "\n",
    "            if line:\n",
    "                if line.startswith(\"@\"):  # Read meta-data\n",
    "                    if not line.startswith(\"@data\"):\n",
    "                        line_content = line.split(\" \")\n",
    "                        if line.startswith(\"@attribute\"):\n",
    "                            if (\n",
    "                                len(line_content) != 3\n",
    "                            ):  # Attributes have both name and type\n",
    "                                raise Exception(\"Invalid meta-data specification.\")\n",
    "\n",
    "                            col_names.append(line_content[1])\n",
    "                            col_types.append(line_content[2])\n",
    "                        else:\n",
    "                            if (\n",
    "                                len(line_content) != 2\n",
    "                            ):  # Other meta-data have only values\n",
    "                                raise Exception(\"Invalid meta-data specification.\")\n",
    "\n",
    "                            if line.startswith(\"@frequency\"):\n",
    "                                frequency = line_content[1]\n",
    "                            elif line.startswith(\"@horizon\"):\n",
    "                                forecast_horizon = int(line_content[1])\n",
    "                            elif line.startswith(\"@missing\"):\n",
    "                                contain_missing_values = bool(\n",
    "                                    strtobool(line_content[1])\n",
    "                                )\n",
    "                            elif line.startswith(\"@equallength\"):\n",
    "                                contain_equal_length = bool(strtobool(line_content[1]))\n",
    "\n",
    "                    else:\n",
    "                        if len(col_names) == 0:\n",
    "                            raise Exception(\n",
    "                                \"Missing attribute section. Attribute section must come before data.\"\n",
    "                            )\n",
    "\n",
    "                        found_data_tag = True\n",
    "                elif not line.startswith(\"#\"):\n",
    "                    if len(col_names) == 0:\n",
    "                        raise Exception(\n",
    "                            \"Missing attribute section. Attribute section must come before data.\"\n",
    "                        )\n",
    "                    elif not found_data_tag:\n",
    "                        raise Exception(\"Missing @data tag.\")\n",
    "                    else:\n",
    "                        if not started_reading_data_section:\n",
    "                            started_reading_data_section = True\n",
    "                            found_data_section = True\n",
    "                            all_series = []\n",
    "\n",
    "                            for col in col_names:\n",
    "                                all_data[col] = []\n",
    "\n",
    "                        full_info = line.split(\":\")\n",
    "\n",
    "                        if len(full_info) != (len(col_names) + 1):\n",
    "                            raise Exception(\"Missing attributes/values in series.\")\n",
    "\n",
    "                        series = full_info[len(full_info) - 1]\n",
    "                        series = series.split(\",\")\n",
    "\n",
    "                        if len(series) == 0:\n",
    "                            raise Exception(\n",
    "                                \"A given series should contains a set of comma separated numeric values. At least one numeric value should be there in a series. Missing values should be indicated with ? symbol\"\n",
    "                            )\n",
    "\n",
    "                        numeric_series = []\n",
    "\n",
    "                        for val in series:\n",
    "                            if val == \"?\":\n",
    "                                numeric_series.append(replace_missing_vals_with)\n",
    "                            else:\n",
    "                                numeric_series.append(float(val))\n",
    "\n",
    "                        if numeric_series.count(replace_missing_vals_with) == len(\n",
    "                            numeric_series\n",
    "                        ):\n",
    "                            raise Exception(\n",
    "                                \"All series values are missing. A given series should contains a set of comma separated numeric values. At least one numeric value should be there in a series.\"\n",
    "                            )\n",
    "\n",
    "                        all_series.append(pd.Series(numeric_series).array)\n",
    "\n",
    "                        for i in range(len(col_names)):\n",
    "                            att_val = None\n",
    "                            if col_types[i] == \"numeric\":\n",
    "                                att_val = int(full_info[i])\n",
    "                            elif col_types[i] == \"string\":\n",
    "                                att_val = str(full_info[i])\n",
    "                            elif col_types[i] == \"date\":\n",
    "                                att_val = datetime.strptime(\n",
    "                                    full_info[i], \"%Y-%m-%d %H-%M-%S\"\n",
    "                                )\n",
    "                            else:\n",
    "                                raise Exception(\n",
    "                                    \"Invalid attribute type.\"\n",
    "                                )  # Currently, the code supports only numeric, string and date types. Extend this as required.\n",
    "\n",
    "                            if att_val is None:\n",
    "                                raise Exception(\"Invalid attribute value.\")\n",
    "                            else:\n",
    "                                all_data[col_names[i]].append(att_val)\n",
    "\n",
    "                line_count = line_count + 1\n",
    "\n",
    "        if line_count == 0:\n",
    "            raise Exception(\"Empty file.\")\n",
    "        if len(col_names) == 0:\n",
    "            raise Exception(\"Missing attribute section.\")\n",
    "        if not found_data_section:\n",
    "            raise Exception(\"Missing series information under data section.\")\n",
    "\n",
    "        all_data[value_column_name] = all_series\n",
    "        loaded_data = pd.DataFrame(all_data)\n",
    "\n",
    "        return (\n",
    "            loaded_data,\n",
    "            frequency,\n",
    "            forecast_horizon,\n",
    "            contain_missing_values,\n",
    "            contain_equal_length,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_dict = {'nn5_daily_dataset_without_missing_values': 'D',\n",
    "                  'nn5_weekly_dataset': 'W-MON',\n",
    "                  'london_smart_meters_dataset_without_missing_values': '30min', \n",
    "                  'car_parts_dataset_without_missing_values': 'MS',\n",
    "                  'covid_deaths_dataset':'D',\n",
    "                  'solar_10_minutes_dataset': '10min',\n",
    "                  'hospital_dataset': 'MS',\n",
    "                  'electricity_hourly_dataset': 'H',\n",
    "                  'electricity_weekly_dataset': 'W-SUN',\n",
    "                  'pedestrian_counts_dataset': 'H',\n",
    "                  'kdd_cup_2018_dataset_without_missing_values': 'H',\n",
    "                  'wind_farms_minutely_dataset_without_missing_values': 'T',}\n",
    "\n",
    "data_dict = {'nn5_daily_dataset_without_missing_values': 'nn5_daily',\n",
    "             'nn5_weekly_dataset': 'nn5_weekly',\n",
    "             'london_smart_meters_dataset_without_missing_values': 'london_smart_meters',\n",
    "             'car_parts_dataset_without_missing_values': 'car_parts',\n",
    "             'covid_deaths_dataset': 'covid_deaths',\n",
    "             'solar_10_minutes_dataset': 'solar_alabama',\n",
    "             'hospital_dataset': 'hospital',\n",
    "             'electricity_hourly_dataset': 'electricity_hourly',\n",
    "             'electricity_weekly_dataset': 'electricity_weekly',\n",
    "             'pedestrian_counts_dataset': 'pedestrian_counts',\n",
    "             'kdd_cup_2018_dataset_without_missing_values': 'kdd_cup_2018',\n",
    "             'wind_farms_minutely_dataset_without_missing_values': 'wind_farms'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_time_series(unique_id, start, periods, values, freq):\n",
    "    total_dates = pd.date_range(start=start, periods=periods, freq=freq)\n",
    "    time_series = pd.DataFrame({'ts_name': unique_id, 'ds': total_dates, 'y': values})\n",
    "    return time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(loaded_data, frequency):\n",
    "    loaded_data['count'] = loaded_data['series_value'].apply(lambda x: len(x))\n",
    "    data = pd.concat([_create_time_series(row[1]['series_name'],\n",
    "                                          row[1]['start_timestamp'],\n",
    "                                          row[1]['count'],\n",
    "                                          row[1]['series_value'],\n",
    "                                          frequency) for row in loaded_data.iterrows()])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets = ['nn5_daily_dataset_without_missing_values',\n",
    "#             'nn5_weekly_dataset',\n",
    "#             'london_smart_meters_dataset_without_missing_values',\n",
    "#             'car_parts_dataset_without_missing_values',\n",
    "#             'covid_deaths_dataset',\n",
    "#             'solar_10_minutes_dataset',\n",
    "#             'hospital_dataset',\n",
    "#             'electricity_hourly_dataset',\n",
    "#             'electricity_weekly_dataset',\n",
    "#             'pedestrian_counts_dataset',\n",
    "#             'kdd_cup_2018_dataset_without_missing_values']\n",
    "datasets =   ['wind_farms_minutely_dataset_without_missing_values']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:  wind_farms_minutely_dataset_without_missing_values\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "for data_name in datasets:\n",
    "    print('data: ', data_name)\n",
    "    loaded_data, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(f\"data_monash/{data_name}.tsf\")\n",
    "    data = parse_data(loaded_data=loaded_data, frequency=frequency_dict[data_name])\n",
    "    data['dataset'] = data_dict[data_name]\n",
    "    data['frequency'] = frequency_dict[data_name]\n",
    "    data_list.append(data)\n",
    "complete_data = pd.concat(data_list).reset_index(drop=True)\n",
    "complete_data['to_hash'] = complete_data['dataset'] + '_' + complete_data['ts_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data['unique_id'] = complete_data['to_hash'].apply(lambda x: hashlib.sha1(x.encode()).hexdigest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data = complete_data[['unique_id', 'ds', 'y', 'dataset', 'ts_name', 'frequency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ts_name</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dc5d029dde0bbe049393495a3bbc4289de62fe3c</td>\n",
       "      <td>2019-08-01 00:00:01</td>\n",
       "      <td>559.0</td>\n",
       "      <td>wind_farms</td>\n",
       "      <td>T1</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dc5d029dde0bbe049393495a3bbc4289de62fe3c</td>\n",
       "      <td>2019-08-01 00:01:01</td>\n",
       "      <td>560.0</td>\n",
       "      <td>wind_farms</td>\n",
       "      <td>T1</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dc5d029dde0bbe049393495a3bbc4289de62fe3c</td>\n",
       "      <td>2019-08-01 00:02:01</td>\n",
       "      <td>559.0</td>\n",
       "      <td>wind_farms</td>\n",
       "      <td>T1</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dc5d029dde0bbe049393495a3bbc4289de62fe3c</td>\n",
       "      <td>2019-08-01 00:03:01</td>\n",
       "      <td>558.0</td>\n",
       "      <td>wind_farms</td>\n",
       "      <td>T1</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dc5d029dde0bbe049393495a3bbc4289de62fe3c</td>\n",
       "      <td>2019-08-01 00:04:01</td>\n",
       "      <td>559.0</td>\n",
       "      <td>wind_farms</td>\n",
       "      <td>T1</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172178055</th>\n",
       "      <td>25c7c70018578ff8b5491c0ccdef05480b9c6f91</td>\n",
       "      <td>2020-07-31 23:55:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wind_farms</td>\n",
       "      <td>T339</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172178056</th>\n",
       "      <td>25c7c70018578ff8b5491c0ccdef05480b9c6f91</td>\n",
       "      <td>2020-07-31 23:56:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wind_farms</td>\n",
       "      <td>T339</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172178057</th>\n",
       "      <td>25c7c70018578ff8b5491c0ccdef05480b9c6f91</td>\n",
       "      <td>2020-07-31 23:57:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wind_farms</td>\n",
       "      <td>T339</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172178058</th>\n",
       "      <td>25c7c70018578ff8b5491c0ccdef05480b9c6f91</td>\n",
       "      <td>2020-07-31 23:58:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wind_farms</td>\n",
       "      <td>T339</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172178059</th>\n",
       "      <td>25c7c70018578ff8b5491c0ccdef05480b9c6f91</td>\n",
       "      <td>2020-07-31 23:59:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>wind_farms</td>\n",
       "      <td>T339</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172178060 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          unique_id                  ds  \\\n",
       "0          dc5d029dde0bbe049393495a3bbc4289de62fe3c 2019-08-01 00:00:01   \n",
       "1          dc5d029dde0bbe049393495a3bbc4289de62fe3c 2019-08-01 00:01:01   \n",
       "2          dc5d029dde0bbe049393495a3bbc4289de62fe3c 2019-08-01 00:02:01   \n",
       "3          dc5d029dde0bbe049393495a3bbc4289de62fe3c 2019-08-01 00:03:01   \n",
       "4          dc5d029dde0bbe049393495a3bbc4289de62fe3c 2019-08-01 00:04:01   \n",
       "...                                             ...                 ...   \n",
       "172178055  25c7c70018578ff8b5491c0ccdef05480b9c6f91 2020-07-31 23:55:00   \n",
       "172178056  25c7c70018578ff8b5491c0ccdef05480b9c6f91 2020-07-31 23:56:00   \n",
       "172178057  25c7c70018578ff8b5491c0ccdef05480b9c6f91 2020-07-31 23:57:00   \n",
       "172178058  25c7c70018578ff8b5491c0ccdef05480b9c6f91 2020-07-31 23:58:00   \n",
       "172178059  25c7c70018578ff8b5491c0ccdef05480b9c6f91 2020-07-31 23:59:00   \n",
       "\n",
       "               y     dataset ts_name frequency  \n",
       "0          559.0  wind_farms      T1         T  \n",
       "1          560.0  wind_farms      T1         T  \n",
       "2          559.0  wind_farms      T1         T  \n",
       "3          558.0  wind_farms      T1         T  \n",
       "4          559.0  wind_farms      T1         T  \n",
       "...          ...         ...     ...       ...  \n",
       "172178055    0.0  wind_farms    T339         T  \n",
       "172178056    0.0  wind_farms    T339         T  \n",
       "172178057    0.0  wind_farms    T339         T  \n",
       "172178058    0.0  wind_farms    T339         T  \n",
       "172178059    0.0  wind_farms    T339         T  \n",
       "\n",
       "[172178060 rows x 6 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data.to_parquet('monash_2.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "STOP",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39m1\u001b[39m\u001b[39m<\u001b[39m\u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mSTOP\u001b[39m\u001b[39m'\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: STOP"
     ]
    }
   ],
   "source": [
    "assert 1<0, 'STOP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_data, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(\"data_monash/nn5_daily_dataset_without_missing_values.tsf\")            # DONE\n",
    "#loaded_data, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(\"data_monash/nn5_weekly_dataset.tsf\")                                  # DONE\n",
    "#loaded_data, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(\"data_monash/london_smart_meters_dataset_without_missing_values.tsf\")  # DONE\n",
    "#loaded_data, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(\"data_monash/car_parts_dataset_without_missing_values.tsf\")            # DONE\n",
    "#loaded_data, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(\"data_monash/covid_deaths_dataset.tsf\")                                # DONE\n",
    "#loaded_data, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(\"data_monash/solar_10_minutes_dataset.tsf\")                            # DONE\n",
    "#loaded_data, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(\"data_monash/hospital_dataset.tsf\")                                    # DONE\n",
    "#loaded_data, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(\"data_monash/electricity_hourly_dataset.tsf\")                          # DONE\n",
    "#loaded_data, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(\"data_monash/wind_farms_minutely_dataset_without_missing_values.tsf\")  # DONE\n",
    "#loaded_data, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(\"data_monash/kdd_cup_2018_dataset_without_missing_values.tsf\")         # DONE\n",
    "#loaded_data, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(\"data_monash/pedestrian_counts_dataset.tsf\")                           # DONE\n",
    "\n",
    "#loaded_data, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(\"data_monash/weather_dataset.tsf\")                                     # no date\n",
    "#loaded_data, frequency, forecast_horizon, contain_missing_values, contain_equal_length = convert_tsf_to_dataframe(\"data_monash/dominick_dataset.tsf\")                                    # no date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contain_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contain_equal_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_dict = {'half_hourly': '30min',\n",
    "                  'daily': 'D',\n",
    "                  '10_minutes': '10min',\n",
    "                  'hourly': 'H',\n",
    "                  'monthly': 'MS', # CUIDADO\n",
    "                  'minutely': 'T',\n",
    "                  'weekly': 'W-SUN'}  # CUIDADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_time_series(unique_id, start, periods, values, freq):\n",
    "    total_dates = pd.date_range(start=start, periods=periods, freq=freq)\n",
    "    time_series = pd.DataFrame({'unique_id': unique_id, 'ds': total_dates, 'y': values})\n",
    "    return time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_data(loaded_data, frequency):\n",
    "    loaded_data['count'] = loaded_data['series_value'].apply(lambda x: len(x))\n",
    "    data = pd.concat([_create_time_series(row[1]['series_name'],\n",
    "                                          row[1]['start_timestamp'],\n",
    "                                          row[1]['count'],\n",
    "                                          row[1]['series_value'],\n",
    "                                          frequency) for row in loaded_data.iterrows()])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = parse_data(loaded_data=loaded_data, frequency=frequency_dict[frequency])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralforecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
