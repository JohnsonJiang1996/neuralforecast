{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpx0i3xtiv\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpx0i3xtiv/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasetsforecast.m4 import M4\n",
    "from config_models import MODEL_LIST\n",
    "\n",
    "from neuralforecast.losses.numpy import mae, mse, smape, mqloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df, a, b = M4.load(directory='./', group='Monthly', cache=True)\n",
    "y = Y_df.groupby('unique_id').tail(12).reset_index(drop=True)['y']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "M4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_dataset = 'M4'\n",
    "# target_dataset = 'M4'\n",
    "# experiment_id = '20230606'\n",
    "\n",
    "# models = ['automlp', 'autonhits','autotft','autopatchtst', 'autotcn', 'autolstm']\n",
    "# model_parse = {\n",
    "#                 'autonhits': 'NHITS',\n",
    "#                 'autotft': 'TFT',\n",
    "#                 'autopatchtst': 'PatchTST',\n",
    "#                 'automlp': 'MLP',\n",
    "#                 'autotcn': 'TCN',\n",
    "#                 'autolstm': 'LSTM',\n",
    "#               }\n",
    "\n",
    "# for model in models:\n",
    "#     model_name = model_parse[model]\n",
    "#     print('Model:', model_name)\n",
    "#     results_df = pd.read_csv(f'./results/forecasts/{target_dataset}/{model}_{source_dataset}_{experiment_id}.csv')\n",
    "#     if target_dataset == 'M4':\n",
    "#       results_df['y'] = y\n",
    "#     #results_df = results_df.groupby('unique_id').tail(12)\n",
    "\n",
    "#     smape_loss = smape(results_df['y'], results_df.iloc[:,3])\n",
    "#     mae_loss = mae(results_df['y'], results_df.iloc[:,3])\n",
    "#     print('smape:', smape_loss)\n",
    "#     print('mae:', mae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source_dataset = 'M4'\n",
    "# target_dataset = 'M3'\n",
    "# experiment_id = '20230606'\n",
    "\n",
    "# models = ['automlp', 'autonhits','autotft','autopatchtst', 'autotcn', 'autolstm']\n",
    "# model_parse = {\n",
    "#                 'autonhits': 'NHITS',\n",
    "#                 'autotft': 'TFT',\n",
    "#                 'autopatchtst': 'PatchTST',\n",
    "#                 'automlp': 'MLP',\n",
    "#                 'autotcn': 'TCN',\n",
    "#                 'autolstm': 'LSTM',\n",
    "#               }\n",
    "\n",
    "# for model in models:\n",
    "#     model_name = model_parse[model]\n",
    "#     print('Model:', model_name)\n",
    "#     results_df = pd.read_csv(f'./results/forecasts/{target_dataset}/{model}_{source_dataset}_{experiment_id}.csv')\n",
    "#     if target_dataset == 'M4':\n",
    "#       results_df['y'] = y\n",
    "#     #results_df = results_df.groupby('unique_id').tail(12)\n",
    "\n",
    "#     smape_loss = smape(results_df['y'], results_df[model_name])\n",
    "#     mae_loss = mae(results_df['y'], results_df[model_name])\n",
    "#     print('smape:', smape_loss)\n",
    "#     print('mae:', mae_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: nhits_15_512\n",
      "smape: 0.14747429369933274\n",
      "mae: 656.23565581285\n",
      "mqloss: 265.41630900681207\n",
      "Model: nhits_30_1024\n",
      "smape: 0.14541996181886246\n",
      "mae: 649.5826373482727\n",
      "mqloss: 264.18316240930994\n",
      "Model: nhits_30_2048\n",
      "smape: 0.14645092800328163\n",
      "mae: 650.5023547718254\n",
      "mqloss: 263.1996163726084\n",
      "Model: patchtst_128_3\n",
      "smape: 0.1520823539944732\n",
      "mae: 704.2193241100606\n",
      "mqloss: 278.0112706847326\n",
      "Model: patchtst_512_6\n",
      "smape: 0.1474111581489757\n",
      "mae: 668.2095220694445\n",
      "mqloss: 270.0446589497616\n",
      "Model: patchtst_1024_6\n",
      "smape: 0.14876738406166748\n",
      "mae: 681.4438905987396\n",
      "mqloss: 277.96903409246147\n",
      "Model: tft_128\n",
      "smape: 0.1447438766587527\n",
      "mae: 652.6071338106909\n",
      "mqloss: 265.77370940031113\n",
      "Model: tft_512\n",
      "smape: 0.14560140590324705\n",
      "mae: 650.7781857201213\n",
      "mqloss: 264.5692171961994\n",
      "Model: tft_1024\n",
      "smape: 0.1466067503614752\n",
      "mae: 656.591426131536\n",
      "mqloss: 267.31999285811315\n",
      "Model: mlp_512_8\n",
      "smape: 0.14631907943211472\n",
      "mae: 657.2981284926472\n",
      "mqloss: 265.3993284891515\n",
      "Model: mlp_2048_32\n",
      "smape: 0.17495658698632544\n",
      "mae: 833.815882556606\n",
      "mqloss: 327.8938141377127\n",
      "Model: tcn_128_3\n",
      "smape: 0.33982558886059905\n",
      "mae: 1609.2892800594652\n",
      "mqloss: 728.646295825617\n",
      "Model: tcn_512_5\n",
      "smape: 0.28738032724587653\n",
      "mae: 1353.704921216328\n",
      "mqloss: 566.6857653143559\n",
      "Model: lstm_128_3\n",
      "smape: 0.2527618800386692\n",
      "mae: 1231.0696142757936\n",
      "mqloss: 542.4399756948989\n",
      "Model: lstm_512_5\n",
      "smape: 0.20709900241027002\n",
      "mae: 1022.2760193469887\n",
      "mqloss: 451.04989897935883\n"
     ]
    }
   ],
   "source": [
    "source_dataset = 'M4'\n",
    "target_dataset = 'M3'\n",
    "experiment_id = '20230621'\n",
    "\n",
    "for model in MODEL_LIST:\n",
    "    print('Model:', model)\n",
    "    results_df = pd.read_csv(f'./results/forecasts/{target_dataset}/{model}_{source_dataset}_{experiment_id}.csv').reset_index(drop=True)\n",
    "    #print('results_df', results_df.columns)\n",
    "    if target_dataset == 'M4':\n",
    "      results_df['y'] = y\n",
    "    results_df = results_df.groupby('unique_id').tail(12)\n",
    "\n",
    "    smape_loss = smape(results_df['y'], results_df.iloc[:,8])\n",
    "    mae_loss = mae(results_df['y'], results_df.iloc[:,8])\n",
    "    mq_loss = mqloss(y=results_df['y'], y_hat=results_df.iloc[:,4:13], quantiles=np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]))\n",
    "    print('smape:', smape_loss)\n",
    "    print('mae:', mae_loss)\n",
    "    print('mqloss:', mq_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1):\n",
    "#     unique_id = results_df['unique_id'].unique()[np.random.randint(1)]\n",
    "#     plot_df = results_df.query('unique_id == @unique_id')\n",
    "\n",
    "#     plt.figure(figsize=(20, 5))\n",
    "#     plt.plot(plot_df['y'], label='y')\n",
    "#     plt.plot(plot_df[model_name], label='y_hat')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as npx\n",
    "\n",
    "from datasetsforecast.m4 import M4\n",
    "from datasetsforecast.m3 import M3\n",
    "from datasetsforecast.long_horizon import LongHorizon\n",
    "from datasetsforecast.losses import mae\n",
    "from statsforecast.utils import AirPassengersDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import AutoARIMA, AutoETS, Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dataset = 'TrafficL'\n",
    "horizon = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (target_dataset == 'AirPassengers'):\n",
    "    Y_df_target = AirPassengersDF.copy()\n",
    "    Y_df_target['ds'] = pd.to_datetime(Y_df_target['ds'])\n",
    "    test_size = horizon\n",
    "    frequency = 'M'\n",
    "elif (target_dataset == 'M3'):\n",
    "    Y_df_target, *_ = M3.load(directory='./', group='Monthly')\n",
    "    Y_df_target['ds'] = pd.to_datetime(Y_df_target['ds'])\n",
    "    frequency = 'M'\n",
    "    test_size = horizon\n",
    "elif (target_dataset == 'M4'):\n",
    "    Y_df_target, *_ = M4.load(directory='./', group='Monthly', cache=True)\n",
    "    Y_df_target['ds'] = pd.to_datetime(Y_df_target['ds'])\n",
    "    frequency = 'M'\n",
    "    test_size = horizon\n",
    "elif (target_dataset == 'ILI'):\n",
    "    Y_df_target, _, _ = LongHorizon.load(directory='./', group='ILI')\n",
    "    Y_df_target['ds'] = np.repeat(np.array(range(len(Y_df_target)//7)), 7)\n",
    "    test_size = horizon\n",
    "    frequency = 'W'\n",
    "elif (target_dataset == 'TrafficL'):\n",
    "    Y_df_target, _, _ = LongHorizon.load(directory='./', group='TrafficL')\n",
    "    Y_df_target['ds'] = np.repeat(np.array(range(len(Y_df_target)//862)), 862)\n",
    "    test_size = horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = Y_df_target['unique_id'].unique()\n",
    "unique_ids = np.random.choice(unique_ids,size=20)\n",
    "Y_df_target = Y_df_target[Y_df_target['unique_id'].isin(unique_ids)].reset_index(drop=True)\n",
    "Y_df_target = Y_df_target.groupby('unique_id').tail(200).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_length = 12 # Monthly data \n",
    "#season_length = 24 # Monthly data \n",
    "\n",
    "# Include the models you imported\n",
    "models = [\n",
    "    AutoARIMA(season_length=season_length),\n",
    "    #AutoETS(season_length=season_length),\n",
    "    Naive()\n",
    "]\n",
    "\n",
    "# Instansiate the StatsForecast class as sf\n",
    "sf = StatsForecast(\n",
    "    df=Y_df_target,\n",
    "    models=models,\n",
    "    freq='M', \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "crossvalidation_df = sf.cross_validation(\n",
    "    df = Y_df_target,\n",
    "    h = horizon,\n",
    "    step_size = 1,\n",
    "    n_windows = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossvalidation_df = crossvalidation_df.reset_index(drop=True)\n",
    "crossvalidation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in ['AutoARIMA', 'Naive']:\n",
    "    print('Model:', model_name)\n",
    "    mae_loss = mae(crossvalidation_df['y'], crossvalidation_df[model_name])\n",
    "    print('mae:', mae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralforecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
