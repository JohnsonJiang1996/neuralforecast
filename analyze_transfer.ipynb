{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasetsforecast.m4 import M4\n",
    "from config_models import MODEL_LIST\n",
    "\n",
    "from neuralforecast.losses.numpy import mae, mse, smape, mqloss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dataset = 'M4'\n",
    "#target_dataset = 'M3'\n",
    "k_shot=0\n",
    "experiment_id = '20230813'\n",
    "\n",
    "#final_df = pd.DataFrame(columns=['model', 'smape', 'mae', 'mqloss'])\n",
    "mae_df = pd.DataFrame(columns = ['dataset', 'frequency'] + MODEL_LIST)\n",
    "smape_df = pd.DataFrame(columns = ['dataset', 'frequency'] + MODEL_LIST)\n",
    "mqloss_df = pd.DataFrame(columns = ['dataset', 'frequency'] + MODEL_LIST)\n",
    "\n",
    "for target_dataset in ['M3']: # , 'AirPassengers', 'ILI', 'TrafficL'\n",
    "    for frequency in ['yearly','quarterly','monthly','daily']:\n",
    "        mae_list = []\n",
    "        smape_list = []\n",
    "        mqloss_list = []\n",
    "        for model in MODEL_LIST:\n",
    "            results_df = pd.read_csv(f'./results/transferability/forecasts/{target_dataset}/{frequency}/{model}_{k_shot}_{source_dataset}_{experiment_id}.csv').reset_index(drop=True)\n",
    "            #print(results_df.shape)\n",
    "            #results_df = results_df.groupby('unique_id').head(12)\n",
    "            #print(results_df.shape)\n",
    "\n",
    "            smape_loss = 100*smape(results_df['y'], results_df.iloc[:,8])\n",
    "            mae_loss = mae(results_df['y'], results_df.iloc[:,8])\n",
    "            mq_loss = mqloss(y=results_df['y'], y_hat=results_df.iloc[:,4:13], quantiles=np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]))\n",
    "            mae_list.append(np.round(mae_loss,3))\n",
    "            smape_list.append(np.round(smape_loss,3))\n",
    "            mqloss_list.append(np.round(mq_loss,3))\n",
    "\n",
    "        mae_df = pd.concat([mae_df, pd.DataFrame({'dataset': [target_dataset], 'frequency': [frequency], **dict(zip(MODEL_LIST, mae_list))})], ignore_index=True)\n",
    "        smape_df = pd.concat([smape_df, pd.DataFrame({'dataset': [target_dataset], 'frequency': [frequency], **dict(zip(MODEL_LIST, smape_list))})], ignore_index=True)\n",
    "        mqloss_df = pd.concat([mqloss_df, pd.DataFrame({'dataset': [target_dataset], 'frequency': [frequency], **dict(zip(MODEL_LIST, mqloss_list))})], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(1):\n",
    "#     unique_id = results_df['unique_id'].unique()[np.random.randint(1)]\n",
    "#     plot_df = results_df.query('unique_id == @unique_id')\n",
    "\n",
    "#     plt.figure(figsize=(20, 5))\n",
    "#     plt.plot(plot_df['y'], label='y')\n",
    "#     plt.plot(plot_df[model_name], label='y_hat')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as npx\n",
    "\n",
    "from datasetsforecast.m4 import M4\n",
    "from datasetsforecast.m3 import M3\n",
    "from datasetsforecast.long_horizon import LongHorizon\n",
    "from datasetsforecast.losses import mae\n",
    "from statsforecast.utils import AirPassengersDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import AutoARIMA, AutoETS, Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df_target, *_ = M3.load(directory='./', group='Monthly')\n",
    "Y_df_target['ds'] = pd.to_datetime(Y_df_target['ds'])\n",
    "frequency = 'M'\n",
    "test_size = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_ids = Y_df_target['unique_id'].unique()\n",
    "unique_ids = np.random.choice(unique_ids,size=20)\n",
    "Y_df_target = Y_df_target[Y_df_target['unique_id'].isin(unique_ids)].reset_index(drop=True)\n",
    "Y_df_target = Y_df_target.groupby('unique_id').tail(200).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "season_length = 12 # Monthly data \n",
    "#season_length = 24 # Monthly data \n",
    "\n",
    "# Include the models you imported\n",
    "models = [\n",
    "    AutoARIMA(season_length=season_length),\n",
    "    #AutoETS(season_length=season_length),\n",
    "    Naive()\n",
    "]\n",
    "\n",
    "# Instansiate the StatsForecast class as sf\n",
    "sf = StatsForecast(\n",
    "    df=Y_df_target,\n",
    "    models=models,\n",
    "    freq='M', \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "crossvalidation_df = sf.cross_validation(\n",
    "    df = Y_df_target,\n",
    "    h = horizon,\n",
    "    step_size = 1,\n",
    "    n_windows = 1\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossvalidation_df = crossvalidation_df.reset_index(drop=True)\n",
    "crossvalidation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_name in ['AutoARIMA', 'Naive']:\n",
    "    print('Model:', model_name)\n",
    "    mae_loss = mae(crossvalidation_df['y'], crossvalidation_df[model_name])\n",
    "    print('mae:', mae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralforecast",
   "language": "python",
   "name": "neuralforecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
