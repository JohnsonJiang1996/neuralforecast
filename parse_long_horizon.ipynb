{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "from datasetsforecast.long_horizon import LongHorizon\n",
    "from datasetsforecast.m3 import M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = ['ETTh1', 'ETTh2', 'ETTm1', 'ETTm2', 'ECL', 'Exchange', 'TrafficL', 'Weather', 'ILI']\n",
    "freqs = ['H', 'H', '15T', '15T', '15T', 'D', 'H', '10T', 'W-TUN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETTh1\n",
      "ETTh2\n",
      "ETTm1\n",
      "ETTm2\n",
      "ECL\n",
      "Exchange\n",
      "TrafficL\n",
      "Weather\n",
      "ILI\n"
     ]
    }
   ],
   "source": [
    "Y_df_list = []\n",
    "for i, group in enumerate(groups):\n",
    "    print(group)\n",
    "    Y_df, _, _ = LongHorizon.load(directory='./', group=group)\n",
    "    Y_df['ds'] = pd.to_datetime(Y_df['ds'])\n",
    "    Y_df['frequency'] = freqs[i]\n",
    "    Y_df['dataset'] = group\n",
    "    Y_df['ts_name'] = Y_df['unique_id']\n",
    "    Y_df['to_hash'] = group + '_' + Y_df['unique_id']\n",
    "    Y_df['unique_id'] = Y_df['to_hash'].apply(lambda x: hashlib.sha1(x.encode()).hexdigest())\n",
    "    Y_df = Y_df.drop(columns=['to_hash'])\n",
    "    Y_df = Y_df[['unique_id', 'ds', 'y', 'dataset', 'ts_name', 'frequency']]\n",
    "    Y_df_list.append(Y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df = pd.concat(Y_df_list, axis=0).reset_index(drop=True)\n",
    "Y_df.to_parquet('long_horizon.parquet', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = ['Yearly','Quarterly','Monthly', 'Other']\n",
    "freqs = ['Y', 'Q', 'M', 'D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yearly\n",
      "Quarterly\n",
      "Monthly\n",
      "Other\n"
     ]
    }
   ],
   "source": [
    "Y_df_list = []\n",
    "for i, group in enumerate(groups):\n",
    "    print(group)\n",
    "    Y_df, _, _ = M3.load(directory='./', group=group)\n",
    "    Y_df['ds'] = pd.to_datetime(Y_df['ds'])\n",
    "    Y_df['frequency'] = freqs[i]\n",
    "    Y_df['dataset'] = group\n",
    "    Y_df['ts_name'] = Y_df['unique_id']\n",
    "    Y_df['to_hash'] = group + '_' + Y_df['unique_id']\n",
    "    Y_df['unique_id'] = Y_df['to_hash'].apply(lambda x: hashlib.sha1(x.encode()).hexdigest())\n",
    "    Y_df = Y_df.drop(columns=['to_hash'])\n",
    "    Y_df = Y_df[['unique_id', 'ds', 'y', 'dataset', 'ts_name', 'frequency']]\n",
    "    Y_df_list.append(Y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df = pd.concat(Y_df_list, axis=0).reset_index(drop=True)\n",
    "Y_df.to_parquet('M3.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralforecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
