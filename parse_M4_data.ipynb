{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasetsforecast.m4 import M4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _create_ds(unique_id, start, periods, freq):\n",
    "    try:\n",
    "        total_dates = pd.date_range(start=start, periods=periods, freq=freq)\n",
    "        time_series = pd.DataFrame({'ts_name': unique_id, 'ds': total_dates})\n",
    "    except:\n",
    "        print('unique-id: ', unique_id)\n",
    "        print('start: ', start)\n",
    "        print('periods: ', periods)\n",
    "        print('freq: ', freq)\n",
    "    return time_series"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MONTHLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_monthly(Y_df, dates):\n",
    "\n",
    "    counts = Y_df.groupby('unique_id').count().reset_index()[['unique_id', 'y']]\n",
    "    counts.columns = ['unique_id', 'count']\n",
    "\n",
    "    dates = dates.copy()\n",
    "    dates = dates[dates['SP'] == 'Monthly'].reset_index(drop=True)\n",
    "    dates = dates.merge(counts, left_on='M4id', right_on='unique_id')\n",
    "\n",
    "    def parse_date(x):\n",
    "        if len(x) == 14:\n",
    "            if int(x[6:8]) < 17:\n",
    "                return '20' + x[6:8] + '-' + x[3:5] + '-01'\n",
    "            else:\n",
    "                return '19' + x[6:8] + '-' + x[3:5] + '-01'\n",
    "        elif len(x) == 19:\n",
    "            return x[:10]\n",
    "\n",
    "    dates['StartingDate'] = dates['StartingDate'].apply(parse_date)\n",
    "    assert len(dates[dates['StartingDate'].isnull()]) == 0\n",
    "\n",
    "    ds_df = pd.concat([_create_ds(row[1]['M4id'],\n",
    "                                row[1]['StartingDate'],\n",
    "                                row[1]['count'],\n",
    "                                frequency_map['Monthly']) for row in dates.iterrows()])\n",
    "\n",
    "    ds_df = ds_df.sort_values(by=['ts_name', 'ds']).reset_index(drop=True)\n",
    "    np.all(Y_df['unique_id'] == ds_df['ts_name'])\n",
    "    Y_df['ds'] = ds_df['ds']\n",
    "\n",
    "    return Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_map = {'Monthly': 'MS', 'Quarterly': 'Q', 'Yearly': 'YS', 'Weekly': 'W'}\n",
    "Y_df, _, _ = M4.load(directory='./', group='Monthly', cache=True)\n",
    "dates = pd.read_csv('https://raw.githubusercontent.com/Mcompetitions/M4-methods/master/Dataset/M4-info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df = parse_monthly(Y_df, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df['dataset'] = 'M4_monthly'\n",
    "Y_df['frequency'] = 'MS'\n",
    "Y_df['ts_name'] = Y_df['unique_id']\n",
    "Y_df['to_hash'] = Y_df['dataset'] + '_' + Y_df['unique_id']\n",
    "Y_df['unique_id'] = Y_df['to_hash'].apply(lambda x: hashlib.sha1(x.encode()).hexdigest())\n",
    "Y_df = Y_df[['unique_id', 'ds', 'y', 'dataset', 'ts_name','frequency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df.to_parquet('M4_monthly.parquet', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YEARLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_yearly(Y_df, dates):\n",
    "\n",
    "    counts = Y_df.groupby('unique_id').count().reset_index()[['unique_id', 'y']]\n",
    "    counts.columns = ['unique_id', 'counts']\n",
    "\n",
    "    # Filter older series\n",
    "    to_drop = counts[counts['counts']>200].unique_id.values\n",
    "    Y_df = Y_df[~Y_df['unique_id'].isin(to_drop)].reset_index(drop=True)\n",
    "    counts = counts[~counts['unique_id'].isin(to_drop)].reset_index(drop=True)\n",
    "\n",
    "    dates = dates.copy()\n",
    "    dates = dates[dates['SP'] == 'Yearly'].reset_index(drop=True)\n",
    "    dates = dates.merge(counts, left_on='M4id', right_on='unique_id')\n",
    "\n",
    "    def parse_date(ds, count):\n",
    "        if len(ds) == 14:\n",
    "            year = int(ds[6:8])\n",
    "            if year+2000+count <= 2017:\n",
    "                return '20' + ds[6:8] + '-01-01'\n",
    "            elif year+1900+count <= 2017:\n",
    "                return '19' + ds[6:8] + '-01-01'\n",
    "            elif year+1800+count <= 2017:\n",
    "                return '18' + ds[6:8] + '-01-01'\n",
    "            elif year+1700+count <= 2017:\n",
    "                return '17' + ds[6:8] + '-01-01'\n",
    "            elif year+1600+count <= 2017:\n",
    "                return '16' + ds[6:8] + '-01-01'\n",
    "            else:\n",
    "                print(year)\n",
    "                print(count)\n",
    "                raise Exception('Year is too old')\n",
    "        elif len(ds) == 19:\n",
    "            return ds[:10]\n",
    "\n",
    "    dates['StartingDate'] = dates.apply(lambda x: parse_date(x.StartingDate, x.counts), axis=1)\n",
    "\n",
    "    assert len(dates[dates['StartingDate'].isnull()]) == 0\n",
    "\n",
    "    ds_df = pd.concat([_create_ds(row[1]['M4id'],\n",
    "                                row[1]['StartingDate'],\n",
    "                                row[1]['counts'],\n",
    "                                frequency_map['Yearly']) for row in dates.iterrows()])\n",
    "\n",
    "    ds_df = ds_df.sort_values(by=['ts_name', 'ds']).reset_index(drop=True)\n",
    "    np.all(Y_df['unique_id'] == ds_df['ts_name'])\n",
    "    Y_df['ds'] = ds_df['ds']\n",
    "\n",
    "    return Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_map = {'Monthly': 'MS', 'Quarterly': 'Q', 'Yearly': 'YS', 'Weekly': 'W'}\n",
    "Y_df, _, _ = M4.load(directory='./', group='Yearly', cache=True)\n",
    "dates = pd.read_csv('https://raw.githubusercontent.com/Mcompetitions/M4-methods/master/Dataset/M4-info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df = parse_yearly(Y_df, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df['dataset'] = 'M4_yearly'\n",
    "Y_df['frequency'] = 'YS'\n",
    "Y_df['ts_name'] = Y_df['unique_id']\n",
    "Y_df['to_hash'] = Y_df['dataset'] + '_' + Y_df['unique_id']\n",
    "Y_df['unique_id'] = Y_df['to_hash'].apply(lambda x: hashlib.sha1(x.encode()).hexdigest())\n",
    "Y_df = Y_df[['unique_id', 'ds', 'y', 'dataset', 'ts_name','frequency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df.to_parquet('M4_yearly.parquet', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quarterly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_quarterly(Y_df, dates):\n",
    "\n",
    "    counts = Y_df.groupby('unique_id').count().reset_index()[['unique_id', 'y']]\n",
    "    counts.columns = ['unique_id', 'counts']\n",
    "\n",
    "    # Filter older series\n",
    "    to_drop = counts[counts['counts']>800].unique_id.values\n",
    "    Y_df = Y_df[~Y_df['unique_id'].isin(to_drop)].reset_index(drop=True)\n",
    "    counts = counts[~counts['unique_id'].isin(to_drop)].reset_index(drop=True)\n",
    "\n",
    "    dates = dates.copy()\n",
    "    dates = dates[dates['SP'] == 'Quarterly'].reset_index(drop=True)\n",
    "    dates = dates.merge(counts, left_on='M4id', right_on='unique_id')\n",
    "\n",
    "    def parse_date(ds, count):\n",
    "        if len(ds) == 14:\n",
    "            year = int(ds[6:8])\n",
    "            if year+2000+count//4 <= 2017:\n",
    "                return '20' + ds[6:8] + '-' + ds[3:5] + '-01'\n",
    "            elif year+1900+count//4 <= 2017:\n",
    "                return '19' + ds[6:8] + '-' + ds[3:5] + '-01'\n",
    "            elif year+1800+count//4 <= 2017:\n",
    "                return '18' + ds[6:8] + '-' + ds[3:5] + '-01'\n",
    "            elif year+1700+count//4 <= 2017:\n",
    "                return '17' + ds[6:8] + '-' + ds[3:5] + '-01'\n",
    "            elif year+1600+count//4 <= 2017:\n",
    "                return '16' + ds[6:8] + '-' + ds[3:5] + '-01'\n",
    "            else:\n",
    "                print(year)\n",
    "                print(count)\n",
    "                raise Exception('Year is too old')\n",
    "        elif len(ds) == 19:\n",
    "            return ds[:10]\n",
    "\n",
    "    dates['StartingDate'] = dates.apply(lambda x: parse_date(x.StartingDate, x.counts), axis=1)\n",
    "\n",
    "    assert len(dates[dates['StartingDate'].isnull()]) == 0\n",
    "\n",
    "    ds_df = pd.concat([_create_ds(row[1]['M4id'],\n",
    "                                row[1]['StartingDate'],\n",
    "                                row[1]['counts'],\n",
    "                                frequency_map['Quarterly']) for row in dates.iterrows()])\n",
    "\n",
    "    ds_df = ds_df.sort_values(by=['ts_name', 'ds']).reset_index(drop=True)\n",
    "    np.all(Y_df['unique_id'] == ds_df['ts_name'])\n",
    "    Y_df['ds'] = ds_df['ds']\n",
    "\n",
    "    return Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>M4id</th>\n",
       "      <th>category</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Horizon</th>\n",
       "      <th>SP</th>\n",
       "      <th>StartingDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>Macro</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Quarterly</td>\n",
       "      <td>01-01-05 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>Macro</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Quarterly</td>\n",
       "      <td>01-01-05 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>Macro</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Quarterly</td>\n",
       "      <td>01-01-05 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>Macro</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Quarterly</td>\n",
       "      <td>01-01-05 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q5</td>\n",
       "      <td>Macro</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Quarterly</td>\n",
       "      <td>01-01-00 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23995</th>\n",
       "      <td>Q23996</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Quarterly</td>\n",
       "      <td>31-03-97 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23996</th>\n",
       "      <td>Q23997</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Quarterly</td>\n",
       "      <td>31-03-97 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23997</th>\n",
       "      <td>Q23998</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Quarterly</td>\n",
       "      <td>31-03-97 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23998</th>\n",
       "      <td>Q23999</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Quarterly</td>\n",
       "      <td>30-06-99 12:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23999</th>\n",
       "      <td>Q24000</td>\n",
       "      <td>Other</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>Quarterly</td>\n",
       "      <td>30-09-00 12:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         M4id category  Frequency  Horizon         SP    StartingDate\n",
       "0          Q1    Macro          4        8  Quarterly  01-01-05 12:00\n",
       "1          Q2    Macro          4        8  Quarterly  01-01-05 12:00\n",
       "2          Q3    Macro          4        8  Quarterly  01-01-05 12:00\n",
       "3          Q4    Macro          4        8  Quarterly  01-01-05 12:00\n",
       "4          Q5    Macro          4        8  Quarterly  01-01-00 12:00\n",
       "...       ...      ...        ...      ...        ...             ...\n",
       "23995  Q23996    Other          4        8  Quarterly  31-03-97 12:00\n",
       "23996  Q23997    Other          4        8  Quarterly  31-03-97 12:00\n",
       "23997  Q23998    Other          4        8  Quarterly  31-03-97 12:00\n",
       "23998  Q23999    Other          4        8  Quarterly  30-06-99 12:00\n",
       "23999  Q24000    Other          4        8  Quarterly  30-09-00 12:00\n",
       "\n",
       "[24000 rows x 6 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = dates[dates['SP'] == 'Quarterly'].reset_index(drop=True)\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_map = {'Monthly': 'MS', 'Quarterly': 'QS', 'Yearly': 'YS', 'Weekly': 'W'}\n",
    "Y_df, _, _ = M4.load(directory='./', group='Quarterly', cache=True)\n",
    "dates = pd.read_csv('https://raw.githubusercontent.com/Mcompetitions/M4-methods/master/Dataset/M4-info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df = parse_quarterly(Y_df, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df['dataset'] = 'M4_quarterly'\n",
    "Y_df['frequency'] = 'QS'\n",
    "Y_df['ts_name'] = Y_df['unique_id']\n",
    "Y_df['to_hash'] = Y_df['dataset'] + '_' + Y_df['unique_id']\n",
    "Y_df['unique_id'] = Y_df['to_hash'].apply(lambda x: hashlib.sha1(x.encode()).hexdigest())\n",
    "Y_df = Y_df[['unique_id', 'ds', 'y', 'dataset', 'ts_name','frequency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df.to_parquet('M4_quarterly.parquet', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_daily(Y_df, dates):\n",
    "\n",
    "    counts = Y_df.groupby('unique_id').count().reset_index()[['unique_id', 'y']]\n",
    "    counts.columns = ['unique_id', 'counts']\n",
    "\n",
    "    dates = dates.copy()\n",
    "    dates = dates[dates['SP'] == 'Daily'].reset_index(drop=True)\n",
    "    dates = dates.merge(counts, left_on='M4id', right_on='unique_id')\n",
    "\n",
    "    def parse_date(ds, count):\n",
    "        if len(ds) == 14:\n",
    "            year = int(ds[6:8])\n",
    "            if year+2000+count//365 < 2017:\n",
    "                return '20' + ds[6:8] + ds[3:5] + ds[0:2]\n",
    "            elif year+1900+count//365 < 2017:\n",
    "                return '19' + ds[6:8] + ds[3:5] + ds[0:2]\n",
    "            elif year+1800+count//365 < 2017:\n",
    "                return '18' + ds[6:8] + ds[3:5] + ds[0:2]\n",
    "            elif year+1700+count//365 < 2017:\n",
    "                return '17' + ds[6:8] + ds[3:5] + ds[0:2]\n",
    "            elif year+1600+count//365 < 2017:\n",
    "                return '16' + ds[6:8] + ds[3:5] + ds[0:2]\n",
    "            else:\n",
    "                print(year)\n",
    "                print(count)\n",
    "                raise Exception('Year is too old')\n",
    "        elif len(ds) == 19:\n",
    "            return ds[:10]\n",
    "\n",
    "    dates['StartingDate'] = dates.apply(lambda x: parse_date(x.StartingDate, x.counts), axis=1)\n",
    "\n",
    "    assert len(dates[dates['StartingDate'].isnull()]) == 0\n",
    "\n",
    "    ds_df = pd.concat([_create_ds(row[1]['M4id'],\n",
    "                                row[1]['StartingDate'],\n",
    "                                row[1]['counts'],\n",
    "                                frequency_map['Daily']) for row in dates.iterrows()])\n",
    "\n",
    "    ds_df = ds_df.sort_values(by=['ts_name', 'ds']).reset_index(drop=True)\n",
    "    np.all(Y_df['unique_id'] == ds_df['ts_name'])\n",
    "    Y_df['ds'] = ds_df['ds']\n",
    "\n",
    "    return Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_map = {'Monthly': 'MS', 'Quarterly': 'QS', 'Yearly': 'YS', 'Weekly': 'W', 'Daily':'D'}\n",
    "Y_df, _, _ = M4.load(directory='./', group='Daily', cache=True)\n",
    "dates = pd.read_csv('https://raw.githubusercontent.com/Mcompetitions/M4-methods/master/Dataset/M4-info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df = parse_daily(Y_df, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df['dataset'] = 'M4_daily'\n",
    "Y_df['frequency'] = 'D'\n",
    "Y_df['ts_name'] = Y_df['unique_id']\n",
    "Y_df['to_hash'] = Y_df['dataset'] + '_' + Y_df['unique_id']\n",
    "Y_df['unique_id'] = Y_df['to_hash'].apply(lambda x: hashlib.sha1(x.encode()).hexdigest())\n",
    "Y_df = Y_df[['unique_id', 'ds', 'y', 'dataset', 'ts_name','frequency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df.to_parquet('M4_daily.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>dataset</th>\n",
       "      <th>ts_name</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41e523f5ff6069aa70b7ea7d081a315166b00d81</td>\n",
       "      <td>1994-01-03</td>\n",
       "      <td>1017.10</td>\n",
       "      <td>M4_daily</td>\n",
       "      <td>D1</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41e523f5ff6069aa70b7ea7d081a315166b00d81</td>\n",
       "      <td>1994-01-04</td>\n",
       "      <td>1019.30</td>\n",
       "      <td>M4_daily</td>\n",
       "      <td>D1</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41e523f5ff6069aa70b7ea7d081a315166b00d81</td>\n",
       "      <td>1994-01-05</td>\n",
       "      <td>1017.00</td>\n",
       "      <td>M4_daily</td>\n",
       "      <td>D1</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41e523f5ff6069aa70b7ea7d081a315166b00d81</td>\n",
       "      <td>1994-01-06</td>\n",
       "      <td>1019.20</td>\n",
       "      <td>M4_daily</td>\n",
       "      <td>D1</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41e523f5ff6069aa70b7ea7d081a315166b00d81</td>\n",
       "      <td>1994-01-07</td>\n",
       "      <td>1018.70</td>\n",
       "      <td>M4_daily</td>\n",
       "      <td>D1</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10023831</th>\n",
       "      <td>7b0081dd78259bdd3b9d5c46ad3e2ba18922f0a6</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>1262.08</td>\n",
       "      <td>M4_daily</td>\n",
       "      <td>D999</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10023832</th>\n",
       "      <td>7b0081dd78259bdd3b9d5c46ad3e2ba18922f0a6</td>\n",
       "      <td>2016-08-17</td>\n",
       "      <td>1262.78</td>\n",
       "      <td>M4_daily</td>\n",
       "      <td>D999</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10023833</th>\n",
       "      <td>7b0081dd78259bdd3b9d5c46ad3e2ba18922f0a6</td>\n",
       "      <td>2016-08-18</td>\n",
       "      <td>1264.66</td>\n",
       "      <td>M4_daily</td>\n",
       "      <td>D999</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10023834</th>\n",
       "      <td>7b0081dd78259bdd3b9d5c46ad3e2ba18922f0a6</td>\n",
       "      <td>2016-08-19</td>\n",
       "      <td>1272.66</td>\n",
       "      <td>M4_daily</td>\n",
       "      <td>D999</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10023835</th>\n",
       "      <td>7b0081dd78259bdd3b9d5c46ad3e2ba18922f0a6</td>\n",
       "      <td>2016-08-20</td>\n",
       "      <td>1272.14</td>\n",
       "      <td>M4_daily</td>\n",
       "      <td>D999</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10023836 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         unique_id         ds        y  \\\n",
       "0         41e523f5ff6069aa70b7ea7d081a315166b00d81 1994-01-03  1017.10   \n",
       "1         41e523f5ff6069aa70b7ea7d081a315166b00d81 1994-01-04  1019.30   \n",
       "2         41e523f5ff6069aa70b7ea7d081a315166b00d81 1994-01-05  1017.00   \n",
       "3         41e523f5ff6069aa70b7ea7d081a315166b00d81 1994-01-06  1019.20   \n",
       "4         41e523f5ff6069aa70b7ea7d081a315166b00d81 1994-01-07  1018.70   \n",
       "...                                            ...        ...      ...   \n",
       "10023831  7b0081dd78259bdd3b9d5c46ad3e2ba18922f0a6 2016-08-16  1262.08   \n",
       "10023832  7b0081dd78259bdd3b9d5c46ad3e2ba18922f0a6 2016-08-17  1262.78   \n",
       "10023833  7b0081dd78259bdd3b9d5c46ad3e2ba18922f0a6 2016-08-18  1264.66   \n",
       "10023834  7b0081dd78259bdd3b9d5c46ad3e2ba18922f0a6 2016-08-19  1272.66   \n",
       "10023835  7b0081dd78259bdd3b9d5c46ad3e2ba18922f0a6 2016-08-20  1272.14   \n",
       "\n",
       "           dataset ts_name frequency  \n",
       "0         M4_daily      D1         D  \n",
       "1         M4_daily      D1         D  \n",
       "2         M4_daily      D1         D  \n",
       "3         M4_daily      D1         D  \n",
       "4         M4_daily      D1         D  \n",
       "...            ...     ...       ...  \n",
       "10023831  M4_daily    D999         D  \n",
       "10023832  M4_daily    D999         D  \n",
       "10023833  M4_daily    D999         D  \n",
       "10023834  M4_daily    D999         D  \n",
       "10023835  M4_daily    D999         D  \n",
       "\n",
       "[10023836 rows x 6 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hourly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_hourly(Y_df, dates):\n",
    "\n",
    "    counts = Y_df.groupby('unique_id').count().reset_index()[['unique_id', 'y']]\n",
    "    counts.columns = ['unique_id', 'counts']\n",
    "\n",
    "    dates = dates.copy()\n",
    "    dates = dates[dates['SP'] == 'Hourly'].reset_index(drop=True)\n",
    "    dates = dates.merge(counts, left_on='M4id', right_on='unique_id')\n",
    "\n",
    "    def parse_date(ds, count):\n",
    "        if len(ds) == 14:\n",
    "            year = int(ds[6:8])\n",
    "            if year+2000+count//(365*24) < 2018:\n",
    "                return '20' + ds[6:8] + '-' + ds[3:5] + '-' + ds[0:2] + ' ' + ds[9:11] + ':00:00'\n",
    "            elif year+1900+count//(365*24) < 2018:\n",
    "                return '19' + ds[6:8] + '-' + ds[3:5] + '-' + ds[0:2] + ' ' + ds[9:11] + ':00:00'\n",
    "            elif year+1800+count//(365*24) < 2018:\n",
    "                return '18' + ds[6:8] + '-' + ds[3:5] + '-' + ds[0:2] + ' ' + ds[9:11] + ':00:00'\n",
    "        if len(ds) == 13:\n",
    "            year = int(ds[6:8])\n",
    "            if year+2000+count//(365*24) < 2018:\n",
    "                return '20' + ds[6:8] + '-' + ds[3:5] + '-' + ds[0:2] + ' ' + ds[9:10] + ':00:00'\n",
    "            elif year+1900+count//(365*24) < 2018:\n",
    "                return '19' + ds[6:8] + '-' + ds[3:5] + '-' + ds[0:2] + ' ' + ds[9:10] + ':00:00'\n",
    "            elif year+1800+count//(365*24) < 2018:\n",
    "                return '18' + ds[6:8] + '-' + ds[3:5] + '-' + ds[0:2] + ' ' + ds[9:10] + ':00:00'\n",
    "\n",
    "    dates['StartingDate'] = dates.apply(lambda x: parse_date(x.StartingDate, x.counts), axis=1)\n",
    "\n",
    "    assert len(dates[dates['StartingDate'].isnull()]) == 0\n",
    "\n",
    "    ds_df = pd.concat([_create_ds(row[1]['M4id'],\n",
    "                                row[1]['StartingDate'],\n",
    "                                row[1]['counts'],\n",
    "                                frequency_map['Hourly']) for row in dates.iterrows()])\n",
    "\n",
    "    ds_df = ds_df.sort_values(by=['ts_name', 'ds']).reset_index(drop=True)\n",
    "    np.all(Y_df['unique_id'] == ds_df['ts_name'])\n",
    "    Y_df['ds'] = ds_df['ds']\n",
    "\n",
    "    return Y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency_map = {'Monthly': 'MS', 'Quarterly': 'QS', 'Yearly': 'YS', 'Weekly': 'W', 'Daily':'D', 'Hourly':'H'}\n",
    "Y_df, _, _ = M4.load(directory='./', group='Hourly', cache=True)\n",
    "dates = pd.read_csv('https://raw.githubusercontent.com/Mcompetitions/M4-methods/master/Dataset/M4-info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df = parse_hourly(Y_df, dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df['dataset'] = 'M4_hourly'\n",
    "Y_df['frequency'] = 'H'\n",
    "Y_df['ts_name'] = Y_df['unique_id']\n",
    "Y_df['to_hash'] = Y_df['dataset'] + '_' + Y_df['unique_id']\n",
    "Y_df['unique_id'] = Y_df['to_hash'].apply(lambda x: hashlib.sha1(x.encode()).hexdigest())\n",
    "Y_df = Y_df[['unique_id', 'ds', 'y', 'dataset', 'ts_name','frequency']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_df.to_parquet('M4_hourly.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralforecast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
